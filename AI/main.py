# main_V3.py (main_tea.py ê¸°ë°˜ + StateGraph ì·¨ë¯¸ ì¶”ì²œ ì—ì´ì „íŠ¸ ì´ì‹)

# --- 1. ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ import ---
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import os
from dotenv import load_dotenv
import requests
import json
from datetime import datetime
from typing import List, TypedDict, Optional
import logging
from fastapi.middleware.cors import CORSMiddleware

# --- 2. ë¡œê¹… ê¸°ë³¸ ì„¤ì • ---
logging.basicConfig(level=logging.INFO, format='%(levelname)s:     %(message)s')

# --- 3. LangChain, LangGraph ë° AI ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ import ---
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import chain
from langchain_pinecone import PineconeVectorStore
from langchain.agents import AgentExecutor, create_openai_tools_agent
from langgraph.graph import StateGraph, END
from langchain_core.tools import tool
from tenacity import retry, stop_after_attempt, wait_fixed
import google.generativeai as genai
from requests.exceptions import Timeout, ConnectionError
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain.tools.retriever import create_retriever_tool
from langchain_core.documents import Document

# --- 4. í™˜ê²½ ì„¤ì • ë° FastAPI ì•± ì´ˆê¸°í™” ---
load_dotenv()
app = FastAPI(
    title="MOIT AI Agent Server v3 (StateGraph ì´ì‹)",
    description="main_tea.py ê¸°ë°˜ ìœ„ì— StateGraph ì·¨ë¯¸ ì¶”ì²œ ì—ì´ì „íŠ¸ë¥¼ ì´ì‹í•œ ë²„ì „",
    version="3.0.0",
)

# --- CORS ë¯¸ë“¤ì›¨ì–´ ì¶”ê°€ ---
origins = ["*"]
app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- AI ëª¨ë¸ ë° API í‚¤ ì„¤ì • ---
try:
    gemini_api_key = os.getenv("GOOGLE_API_KEY")
    if gemini_api_key:
        genai.configure(api_key=gemini_api_key)
    else:
        logging.warning("GOOGLE_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì‚¬ì§„ ë¶„ì„ ê¸°ëŠ¥ì´ ì‘ë™í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
except Exception as e:
    logging.warning(f"Gemini API í‚¤ ì„¤ì • ì‹¤íŒ¨: {e}")

llm = ChatOpenAI(model="gpt-4o-mini")


# --- 5. ë§ˆìŠ¤í„° ì—ì´ì „íŠ¸ ë¡œì§ ì „ì²´ ì •ì˜ ---

class MasterAgentState(TypedDict):
    user_input: dict
    route: str
    final_answer: str

# ë¼ìš°í„° ì •ì˜
router_prompt = ChatPromptTemplate.from_template(
    """ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ ì–´ë–¤ ë‹´ë‹¹ìì—ê²Œ ì „ë‹¬í•´ì•¼ í• ì§€ ê²°ì •í•˜ëŠ” AI ë¼ìš°í„°ì…ë‹ˆë‹¤.
    ì‚¬ìš©ìì˜ ìš”ì²­ì„ ë³´ê³ , ì•„ë˜ ì„¸ ê°€ì§€ ê²½ë¡œ ì¤‘ ê°€ì¥ ì ì ˆí•œ ê²½ë¡œ í•˜ë‚˜ë§Œ ê³¨ë¼ ê·¸ ì´ë¦„ë§Œ ì •í™•íˆ ë‹µë³€í•´ì£¼ì„¸ìš”.
    (meeting_matching, hobby_recommendation, general_search ì¤‘ íƒ1)
 
    [ì‚¬ìš©ì ìš”ì²­]:
    {user_input}
    """
)
router_chain = router_prompt | llm | StrOutputParser()

def route_request(state: MasterAgentState):
    logging.info("--- ROUTING ---")
    user_input = state['user_input']
    
    if isinstance(user_input, dict) and 'survey' in user_input:
        logging.info("ë¼ìš°íŒ… ê²°ì •: hobby_recommendation (Rule-based)")
        return {"route": "hobby_recommendation"}

    try:
        route_decision = router_chain.invoke({"user_input": user_input})
        cleaned_decision = route_decision.strip().lower().replace("'", "").replace('"', '')
    except Exception as e:
        logging.error(f"ë¼ìš°íŒ… ì¤‘ ì˜¤ë¥˜: {e}")
        cleaned_decision = "general_search" 
        
    logging.info(f"ë¼ìš°íŒ… ê²°ì •: {cleaned_decision}")
    return {"route": cleaned_decision}

@tool
def get_current_date() -> str:
    """ì˜¤ëŠ˜ ë‚ ì§œë¥¼ 'YYYYë…„ MMì›” DDì¼' í˜•ì‹ì˜ ë¬¸ìì—´ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return datetime.now().strftime("%Yë…„ %mì›” %dì¼")

# ë²”ìš© ê²€ìƒ‰ ì—ì´ì „íŠ¸
def call_general_search_agent(state: MasterAgentState):
    logging.info("--- CALLING: General Search Agent ---")

    tavily_tool = TavilySearchResults(max_results=3, name="web_search")
    
    # Pinecone ê²€ìƒ‰ ë„êµ¬
    try:
        meeting_index_name = os.getenv("PINECONE_INDEX_NAME_MEETING")
        embedding_function = OpenAIEmbeddings(model='text-embedding-3-large')
        vector_store = PineconeVectorStore.from_existing_index(index_name=meeting_index_name, embedding=embedding_function)
        retriever = vector_store.as_retriever(search_type="similarity", search_kwargs={'k': 3})
        moit_meeting_retriever_tool = create_retriever_tool(
            retriever,
            "moit_internal_meeting_search",
            "MOIT ì„œë¹„ìŠ¤ ë‚´ì— ë“±ë¡ëœ ê¸°ì¡´ ëª¨ì„ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."
        )
    except Exception as e:
        logging.warning(f"Pinecone ë„êµ¬ ì„¤ì • ì‹¤íŒ¨ (ì´ ë„êµ¬ ì—†ì´ ì§„í–‰): {e}")
        moit_meeting_retriever_tool = None

    tools = [tavily_tool, get_current_date]
    if moit_meeting_retriever_tool:
        tools.append(moit_meeting_retriever_tool)

    react_prompt = ChatPromptTemplate.from_messages([
        ("system", "ë‹¹ì‹ ì€ AI ì–´ì‹œìŠ¤í„´íŠ¸ 'MOIT'ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ë„êµ¬ë¥¼ í™œìš©í•´ ë‹µë³€í•˜ì„¸ìš”."),
        MessagesPlaceholder(variable_name="chat_history", optional=True),
        ("human", "{input}"),
        MessagesPlaceholder(variable_name="agent_scratchpad")
    ])
    
    agent = create_openai_tools_agent(llm, tools, react_prompt)
    general_agent_runnable = AgentExecutor(agent=agent, tools=tools, verbose=True)

    try:
        user_question = state['user_input']
        if isinstance(user_question, dict):
            if 'messages' in user_question:
                user_question = user_question['messages'][0][1]
            elif 'title' in user_question:
                user_question = user_question['title']
            else:
                user_question = str(user_question)
    except:
        user_question = str(state['user_input'])

    input_data = {"input": str(user_question), "chat_history": []}
    
    try:
        result = general_agent_runnable.invoke(input_data)
        final_answer = result.get("output", "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        logging.error(f"ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        final_answer = "ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì—¬ ë‹µë³€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
    return {"final_answer": final_answer}

# ëª¨ì„ ë§¤ì¹­ ì—ì´ì „íŠ¸
def call_meeting_matching_agent(state: MasterAgentState):
    logging.info("--- CALLING: Meeting Matching Agent ---")
    return call_general_search_agent(state)


# --- ì·¨ë¯¸ ì¶”ì²œ ì—ì´ì „íŠ¸ ---

def normalize(value, min_val, max_val):
    if value is None: return None
    return round((value - min_val) / (max_val - min_val), 4)

def generate_prompt(profile):
    def get_val(val, format_str="{:.2f}"):
        if val is None: return "N/A"
        if format_str: return format_str.format(val)
        return val

    fsc = profile.get('FSC', {})
    pssr = profile.get('PSSR', {})
    mp = profile.get('MP', {})
    dls = profile.get('DLS', {})
    ip = profile.get('IP', {}) 

    fsc_summary = (f"* **í˜„ì‹¤ì  ì œì•½**: ì‹œê°„({get_val(fsc.get('time_availability'))}), ì˜ˆì‚°({get_val(fsc.get('financial_budget'))}), ì—ë„ˆì§€({get_val(fsc.get('energy_level'))}), ì´ë™ì„±({get_val(fsc.get('mobility'))}) / ì„ í˜¸ê³µê°„: {get_val(fsc.get('preferred_space'), format_str=None)}")
    pssr_summary = (f"* **ì‹¬ë¦¬ì  ìƒíƒœ**: ì‚¬íšŒì  ë¶ˆì•ˆ({get_val(pssr.get('social_anxiety_score'))}), í˜„ì¬ ê³ ë¦½ ìˆ˜ì¤€({get_val(pssr.get('isolation_level'))}) (0:ê³ ë¦½, 1:í™œë°œ)")
    mp_summary = (f"* **ì£¼ìš” ë™ê¸°**: í•µì‹¬ ëª©í‘œëŠ” '{get_val(mp.get('core_motivation'), format_str=None)}' ì…ë‹ˆë‹¤.")
    dls_summary = (f"* **ì‚¬íšŒì„± ì„ í˜¸**: '{get_val(dls.get('preferred_sociality_type'), format_str=None)}' í™œë™ì„ ì„ í˜¸í•©ë‹ˆë‹¤.")
    ip_summary = (f"* **ê´€ì‹¬ì‚¬ í”„ë¡œí•„**: ìì—°({get_val(ip.get('nature_interest'))}), ì°½ì‘({get_val(ip.get('craft_interest'))}), ì§€ì ({get_val(ip.get('intellect_interest'))}), ì˜ˆìˆ ({get_val(ip.get('art_interest'))}), ì‹ ì²´({get_val(ip.get('activity_interest'))})")

    hard_constraints = "\n# â˜…â˜…â˜… ê¸ˆì§€ ê·œì¹™ (Hard Constraints) â˜…â˜…â˜…\n"
    if ip.get('nature_interest', 0.5) < 0.3: hard_constraints += "- 'ìì—°' ê´€ë ¨ í™œë™ ê¸ˆì§€\n"
    if ip.get('craft_interest', 0.5) < 0.3: hard_constraints += "- 'ë§Œë“¤ê¸°' ê´€ë ¨ í™œë™ ê¸ˆì§€\n"
    if ip.get('intellect_interest', 0.5) < 0.3: hard_constraints += "- 'ê³µë¶€/ë…ì„œ' ê´€ë ¨ í™œë™ ê¸ˆì§€\n"
    if ip.get('art_interest', 0.5) < 0.3: hard_constraints += "- 'ì˜ˆìˆ ' ê´€ë ¨ í™œë™ ê¸ˆì§€\n"
    if ip.get('activity_interest', 0.5) < 0.3: hard_constraints += "- 'ì‹ ì²´ í™œë™' ê¸ˆì§€\n"

    prompt = f"""# í˜ë¥´ì†Œë‚˜: ë””ì§€í„¸ ì¹˜ë£Œ ë ˆí¬ë¦¬ì—ì´ì…˜ ì „ë¬¸ê°€
    ì‚¬ìš©ìì˜ í”„ë¡œí•„ì„ ë¶„ì„í•˜ì—¬ ë§ì¶¤í˜• ì·¨ë¯¸ 3ê°€ì§€ë¥¼ ì¶”ì²œí•´ì£¼ì„¸ìš”.
    
    [ì‚¬ìš©ì í”„ë¡œí•„]
    {fsc_summary}
    {pssr_summary}
    {mp_summary}
    {dls_summary}
    {ip_summary}
    {hard_constraints}

    [ê²°ê³¼ í˜•ì‹]
    ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”.
    {{
        "summary": "ì‚¬ìš©ì ë¶„ì„ ìš”ì•½ (ì¹œì ˆí•œ ë§íˆ¬)",
        "recommendations": [
            {{ 
                "name_ko": "ì·¨ë¯¸ì´ë¦„", 
                "short_desc": "í•œì¤„ì„¤ëª…", 
                "reason": "ì¶”ì²œì´ìœ ", 
                "score_total": 95,
                "category": "ì¹´í…Œê³ ë¦¬"
            }},
            ... (3ê°œ)
        ]
    }}
    """
    return prompt

@tool
def analyze_survey_tool(survey_json_string: str) -> dict:
    """ì„¤ë¬¸ ì‘ë‹µ JSON ë¬¸ìì—´ì„ ë¶„ì„í•˜ì—¬ ì‚¬ìš©ìì˜ ì„±í–¥ í”„ë¡œí•„ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    logging.info("--- ğŸ“Š ì„¤ë¬¸ ë¶„ì„ ì‹œì‘ ---")
    try:
        responses = json.loads(survey_json_string)
        
        features = {'FSC': {}, 'PSSR': {}, 'MP': {}, 'DLS': {}, 'IP': {}}
        
        def to_int(q_num_str):
            val = responses.get(q_num_str)
            return int(val) if val is not None else None

        features['FSC']['time_availability'] = normalize(to_int('1'), 1, 4)
        features['FSC']['financial_budget'] = normalize(to_int('2'), 1, 4)
        features['FSC']['energy_level'] = normalize(to_int('3'), 1, 5)
        features['FSC']['mobility'] = normalize(to_int('4'), 1, 5)
        features['FSC']['has_physical_constraints'] = True if to_int('5') in [1, 2, 3] else False
        features['FSC']['has_housing_constraints'] = True if to_int('12') in [2, 3, 4] else False
        features['FSC']['preferred_space'] = 'indoor' if to_int('6') == 1 else 'outdoor'

        q13 = to_int('13') or 3; q14_r = 6 - (to_int('14') or 3); q16 = to_int('16') or 3
        self_criticism_raw = (q13 + q14_r + q16) / 3
        features['PSSR']['self_criticism_score'] = normalize(self_criticism_raw, 1, 5)
        q15 = to_int('15') or 3; q18 = to_int('18') or 3; q20 = to_int('20') or 3
        social_anxiety_raw = (q15 + q18 + q20) / 3
        features['PSSR']['social_anxiety_score'] = normalize(social_anxiety_raw, 1, 5)
        features['PSSR']['isolation_level'] = normalize(to_int('21'), 1, 5)
        features['PSSR']['structure_preference_score'] = normalize(to_int('27'), 1, 5)
        features['PSSR']['avoidant_coping_score'] = normalize(to_int('29'), 1, 5)

        motivation_map = {1: 'ì„±ì·¨', 2: 'íšŒë³µ', 3: 'ì—°ê²°', 4: 'í™œë ¥'}
        features['MP']['core_motivation'] = motivation_map.get(to_int('31'))
        
        sociality_map = {1: 'ë‹¨ë…í˜•', 2: 'ë³‘ë ¬í˜•', 3: 'ì €ê°•ë„ ìƒí˜¸ì‘ìš©í˜•', 4: 'ê³ ê°•ë„ ìƒí˜¸ì‘ìš©í˜•'}
        features['DLS']['preferred_sociality_type'] = sociality_map.get(to_int('39'))
        
        features['IP']['nature_interest'] = normalize(to_int('43'), 1, 5)
        features['IP']['craft_interest'] = normalize(to_int('44'), 1, 5)
        features['IP']['intellect_interest'] = normalize(to_int('45'), 1, 5)
        features['IP']['art_interest'] = normalize(to_int('46'), 1, 5)
        features['IP']['activity_interest'] = normalize(to_int('47'), 1, 5)
        
        return features
    except Exception as e:
        logging.error(f"ì„¤ë¬¸ ë¶„ì„ ì˜¤ë¥˜: {e}")
        return {}

@tool
def analyze_photo_tool(image_paths: list[str], survey_profile: dict) -> str:
    """ì‚¬ìš©ìì˜ ì‚¬ì§„ê³¼ ì„¤ë¬¸ í”„ë¡œí•„ì„ ë°”íƒ•ìœ¼ë¡œ ë§ì¶¤í˜• ì·¨ë¯¸ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤."""
    from PIL import Image
    logging.info(f"--- ğŸ“¸ ì‚¬ì§„ ë¶„ì„ ë° ì¶”ì²œ ìƒì„± ì‹œì‘ ---")
    
    try:
        prompt_text = generate_prompt(survey_profile)
    except:
        prompt_text = "ì‚¬ìš©ìì—ê²Œ ì•Œë§ì€ ì·¨ë¯¸ë¥¼ ì¶”ì²œí•´ì£¼ì„¸ìš”."

    image_parts = []
    if image_paths:
        for path in image_paths:
            try:
                img = Image.open(path)
                image_parts.append(img)
            except Exception as e:
                logging.warning(f"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {path} - {e}")

    try:
        # [í•µì‹¬ ìˆ˜ì •] 404 ì—ëŸ¬ê°€ ë°œìƒí–ˆë˜ ëª¨ë¸ ëŒ€ì‹ , í˜„ì¬ ê°€ì¥ ì•ˆì •ì ì¸ ìµœì‹  ëª¨ë¸ ì‚¬ìš©
        model = genai.GenerativeModel('gemini-2.5-flash') 
        response = model.generate_content([prompt_text] + image_parts) 
        logging.info("--- âœ… Gemini ì‘ë‹µ ì™„ë£Œ ---")
        return response.text
    except Exception as e:
        logging.error(f"Gemini í˜¸ì¶œ ì˜¤ë¥˜: {e}")
        return json.dumps({
            "summary": "ì£„ì†¡í•©ë‹ˆë‹¤. AI ëª¨ë¸ ì—°ê²°ì— ì¼ì‹œì ì¸ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. API í‚¤ì™€ ëª¨ë¸ ì ‘ê·¼ ê¶Œí•œì„ í™•ì¸í•´ ì£¼ì„¸ìš”.",
            "recommendations": []
        }, ensure_ascii=False)

class HobbyAgentState(TypedDict):
    survey_data: dict
    image_paths: List[str]
    survey_profile: dict
    final_recommendation: str

def analyze_survey_node(state: HobbyAgentState):
    survey_json_string = json.dumps(state["survey_data"], ensure_ascii=False)
    survey_profile = analyze_survey_tool.invoke({"survey_json_string": survey_json_string})
    return {"survey_profile": survey_profile}

def analyze_photo_node(state: HobbyAgentState):
    result = analyze_photo_tool.invoke({
        "image_paths": state.get("image_paths", []),
        "survey_profile": state.get("survey_profile", {})
    })
    return {"final_recommendation": result}

hobby_builder = StateGraph(HobbyAgentState)
hobby_builder.add_node("analyze_survey", analyze_survey_node)
hobby_builder.add_node("analyze_photo", analyze_photo_node) 
hobby_builder.set_entry_point("analyze_survey")
hobby_builder.add_edge("analyze_survey", "analyze_photo") 
hobby_builder.add_edge("analyze_photo", END) 
hobby_graph = hobby_builder.compile()

def call_multimodal_hobby_agent(state: MasterAgentState):
    logging.info("--- CALLING: Hobby Agent ---")
    user_input = state['user_input']
    survey_data = user_input.get('survey', {})
    
    if isinstance(survey_data, str):
        try:
            survey_data = json.loads(survey_data)
        except:
            pass

    inputs = {"survey_data": survey_data, "image_paths": []}
    result = hobby_graph.invoke(inputs)
    return {"final_answer": result.get('final_recommendation', "")}

master_builder = StateGraph(MasterAgentState)

master_builder.add_node("router", route_request)
master_builder.add_node("hobby_recommender", call_multimodal_hobby_agent)
master_builder.add_node("general_searcher", call_general_search_agent)

master_builder.set_entry_point("router")
master_builder.add_conditional_edges("router", lambda x: x['route'], {
    "hobby_recommendation": "hobby_recommender",
    "general_search": "general_searcher",
    "meeting_matching": "general_searcher" 
})
master_builder.add_edge("hobby_recommender", END)
master_builder.add_edge("general_searcher", END)
master_agent = master_builder.compile()

class UserRequest(BaseModel):
    user_input: dict

@app.post("/agent/invoke")
async def invoke_agent(request: UserRequest):
    try:
        result = master_agent.invoke({"user_input": request.user_input})
        return {"final_answer": result.get("final_answer", "")}
    except Exception as e:
        logging.error(f"API ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))

class NewMeeting(BaseModel):
    meeting_id: str
    title: str
    description: str
    time: str
    location: str

@app.post("/meetings/add")
async def add_meeting_to_pinecone(meeting: NewMeeting):
    try:
        logging.info(f"--- Pineconeì— ìƒˆë¡œìš´ ëª¨ì„ ì¶”ê°€ ì‹œì‘ (ID: {meeting.meeting_id}) ---")
        meeting_index_name = os.getenv("PINECONE_INDEX_NAME_MEETING")
        if not meeting_index_name: raise ValueError("'.env' íŒŒì¼ì— PINECONE_INDEX_NAME_MEETINGì´(ê°€) ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        embedding_function = OpenAIEmbeddings(model='text-embedding-3-large')
        vector_store = PineconeVectorStore.from_existing_index(index_name=meeting_index_name, embedding=embedding_function)
        
        full_text = f"ì œëª©: {meeting.title}\nì„¤ëª…: {meeting.description}\nì‹œê°„: {meeting.time}\nì¥ì†Œ: {meeting.location}"
        metadata = {
            "title": meeting.title, 
            "description": meeting.description, 
            "time": meeting.time, 
            "location": meeting.location,
            "meeting_id": meeting.meeting_id 
        }
        
        vector_store.add_texts(texts=[full_text], metadatas=[metadata], ids=[meeting.meeting_id])
        
        logging.info(f"--- Pineconeì— ëª¨ì„ ì¶”ê°€ ì„±ê³µ (ID: {meeting.meeting_id}) ---")
        return {"status": "success", "message": f"ëª¨ì„(ID: {meeting.meeting_id})ì´ ì„±ê³µì ìœ¼ë¡œ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤."}
    except Exception as e:
        logging.error(f"Pinecone ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Pineconeì— ëª¨ì„ì„ ì¶”ê°€í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

@app.delete("/meetings/delete/{meeting_id}")
async def delete_meeting_from_pinecone(meeting_id: str):
    try:
        logging.info(f"--- Pineconeì—ì„œ ëª¨ì„ ì‚­ì œ ì‹œì‘ (ID: {meeting_id}) ---")
        meeting_index_name = os.getenv("PINECONE_INDEX_NAME_MEETING")
        if not meeting_index_name: raise ValueError("'.env' íŒŒì¼ì— PINECONE_INDEX_NAME_MEETINGì´(ê°€) ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        embedding_function = OpenAIEmbeddings(model='text-embedding-3-large')
        vector_store = PineconeVectorStore.from_existing_index(index_name=meeting_index_name, embedding=embedding_function)
        
        vector_store.delete(ids=[meeting_id])
        
        logging.info(f"--- Pineconeì—ì„œ ëª¨ì„ ì‚­ì œ ì„±ê³µ (ID: {meeting_id}) ---")
        return {"status": "success", "message": f"ëª¨ì„(ID: {meeting.meeting_id})ì´ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤."}
    except Exception as e:
        logging.error(f"Pinecone ì‚­ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Pineconeì—ì„œ ëª¨ì„ì„ ì‚­ì œí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.: {str(e)}")

# --- 7. (ì¶”ê°€) ì„œë²„ ì‹¤í–‰ ---
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)